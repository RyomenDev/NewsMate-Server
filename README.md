# ğŸ§  NewsMate Backend - RAG Chatbot for News Articles

This is the **backend** for **NewsMate**, a full-stack AI chatbot that answers questions based on real-time news using **Retrieval-Augmented Generation (RAG)**. The backend handles RSS ingestion, embedding generation, vector indexing in Qdrant, chat session tracking in Redis, and API interaction with Gemini.

---

## ğŸ“¦ Tech Stack

- **Node.js** + **Express** â€“ REST API & scheduling
- **@xenova/transformers** â€“ Local embedding generation (MiniLM)
- **Qdrant Cloud** â€“ Vector DB for semantic search
- **Redis** â€“ Session-based caching and history management
- **Gemini API** â€“ LLM response generation

---

## ğŸ“ˆ Embedding Workflow

### ğŸ” 1. RSS Feed Ingestion

- Periodically fetches news articles via RSS (NYTimes, etc.).
- Extracts `title`, `link`, and `content`.

### ğŸ§  2. Embedding Generation

- Uses `@xenova/transformers` pipeline (`all-MiniLM-L6-v2`) for dense vector generation.
- Pools the output and normalizes it (`mean pooling`).

### ğŸ” 3. Deduplication via Hashing

- Each articleâ€™s `link` is hashed (SHA-256) and formatted to a UUID-like string.
- This hash is used as a **unique ID** for Qdrant indexing.
- Before embedding, checks if the article already exists via `qdrant.retrieve()`.

### ğŸ“¥ 4. Vector Storage in Qdrant

- Embeddings are **upserted** to Qdrantâ€™s `news_articles` collection with:
  - `id` (UUID from link hash)
  - `payload`: title, link, content
  - `vector`: dense embedding array

---

## ğŸ§  Chat & RAG Pipeline

### ğŸ“¤ 1. User Query

- The frontend sends a user query to `/chat` via REST or WebSocket.
- Server performs **semantic search** in Qdrant using the query embedding.

### ğŸ“š 2. Context Retrieval

- Top relevant articles (based on cosine similarity) are retrieved from Qdrant.
- Only key context chunks (e.g., title + summary) are selected and cleaned.

### ğŸ¤– 3. Gemini Response

- Retrieved chunks are inserted into the prompt.
- Gemini API generates a grounded answer.

---

## ğŸ§  Redis: Caching & Sessions

- A Redis store maintains **chat session history** (context window per user).
- Each session ID (socket or token-based) maps to:
  - Previous messages
  - Chat state
- Helps maintain **conversational memory** for follow-ups.

---

## ğŸ”Œ API & Socket Interaction

### âœ… REST Endpoints

| Route                 | Method | Description                                                                 |
| --------------------- | ------ | --------------------------------------------------------------------------- |
| `/session`            | GET    | Generate and return a new unique session ID.                                |
| `/chat`               | POST   | Accept user message, retrieve context, call Gemini API, and return a reply. |
| `/history/:sessionId` | GET    | Retrieve chat history from Redis for a specific session ID.                 |
| `/reset`              | POST   | Clear all session data (messages + context) for the given session ID.       |

<!-- | `/articles`           | GET    | Fetch raw news articles from all configured RSS feeds.                      |
| `/embed`              | POST   | Trigger manual re-embedding of latest fetched articles into Qdrant.         | -->

### ğŸ’¬ WebSocket Events (Optional)

- `user_message` â†’ User sends a query
- `bot_reply` â†’ Server returns Gemini's answer
- Allows real-time interaction on the frontend

---

## âš™ï¸ Noteworthy Design Decisions

- ğŸ” **UUID Hashing for Deduplication**: Prevents re-indexing of the same articles and ensures Qdrant ID format compliance.
- ğŸ”„ **Local Embedding with Xenova**: Avoids external APIs, reduces latency and cost.
- ğŸ§µ **Redis-backed Sessions**: Enables stateful multi-turn conversations and easy scaling with expiry.
- ğŸ“„ **Context Cleanup & Chunking**: Limits context to top-N cleaned, deduplicated chunks for optimal prompt size.

---

## ğŸš€ Future Improvements

- Add OpenTelemetry for performance tracing
- Implement queue-based ingestion for scaling
- Add user authentication & persistent session memory
- Rate limit Gemini API to prevent abuse
- Add UI for managing vector collection and logs

---

## ğŸ“ Directory Overview

```bash
server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ qdrantClient.js       # Qdrant vector store utilities
â”‚   â”‚   â””â”€â”€ redisClient.js        # Redis session manager
â”‚   â”‚   â””â”€â”€ gemini.service.js     # Gemini Service manager
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ embeddingScheduler.js # Scheduler for periodic embeddings
â”‚   â”‚   â”œâ”€â”€ xenovaEmbedding.js    # Embedding generator logic
â”‚   â”‚   â””â”€â”€ rssReader.js          # RSS parser
â”‚   â”‚   â””â”€â”€ redisClient.js        # Redis Client
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chat.js               # Chat route (RAG entry point)
â”‚   â””â”€â”€ index.js                 # App bootstrap
â”œâ”€â”€ embeddings.json              # Locally cached embedding dump
```

## ğŸ§ª Running Locally

- Install dependencies

```bash
npm install
```

- Configure .env

```env
PORT=3000
CORS_ORIGIN1=""
CORS_ORIGIN2=""
CORS_ORIGIN3=""

REDIS_URL=""
GEMINI_API_KEY=""


QDRANT_API_KEY=""
QDRANT_ACCESS_URL=""
EMBED_REFRESH_INTERVAL_MS="21600000" # 6 hrs
```

- Start the server

```bash
npm run dev
```
